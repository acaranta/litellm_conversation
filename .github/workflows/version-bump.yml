name: Version Bump and Release

on:
  workflow_dispatch:
    inputs:
      version_type:
        description: 'Version bump type'
        required: true
        default: 'patch'
        type: choice
        options:
        - major
        - minor  
        - patch
      custom_version:
        description: 'Custom version (optional, overrides version_type)'
        required: false
        type: string

jobs:
  bump:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Calculate new version
        id: version
        run: |
          # Get current version from manifest.json
          CURRENT_VERSION=$(python3 -c "import json; print(json.load(open('custom_components/litellm_conversation/manifest.json'))['version'])")
          echo "Current version: $CURRENT_VERSION"
          
          if [ -n "${{ github.event.inputs.custom_version }}" ]; then
            NEW_VERSION="${{ github.event.inputs.custom_version }}"
            echo "Using custom version: $NEW_VERSION"
          else
            # Parse current version
            IFS='.' read -r -a VERSION_PARTS <<< "$CURRENT_VERSION"
            MAJOR=${VERSION_PARTS[0]}
            MINOR=${VERSION_PARTS[1]}
            PATCH=${VERSION_PARTS[2]}
            
            # Bump version based on type
            case "${{ github.event.inputs.version_type }}" in
              "major")
                MAJOR=$((MAJOR + 1))
                MINOR=0
                PATCH=0
                ;;
              "minor")
                MINOR=$((MINOR + 1))
                PATCH=0
                ;;
              "patch")
                PATCH=$((PATCH + 1))
                ;;
            esac
            
            NEW_VERSION="$MAJOR.$MINOR.$PATCH"
            echo "Bumping ${{ github.event.inputs.version_type }} version to: $NEW_VERSION"
          fi
          
          echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT

      - name: Update manifest.json
        run: |
          python3 -c "
          import json
          with open('custom_components/litellm_conversation/manifest.json', 'r') as f:
              manifest = json.load(f)
          manifest['version'] = '${{ steps.version.outputs.new_version }}'
          with open('custom_components/litellm_conversation/manifest.json', 'w') as f:
              json.dump(manifest, f, indent=2)
          "

      - name: Commit version bump
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add custom_components/litellm_conversation/manifest.json
          git commit -m "Bump version to ${{ steps.version.outputs.new_version }}"
          git push

      - name: Create and push tag
        run: |
          git tag -a "v${{ steps.version.outputs.new_version }}" -m "Release v${{ steps.version.outputs.new_version }}"
          git push origin "v${{ steps.version.outputs.new_version }}"

      - name: Generate release notes
        id: release_notes
        run: |
          cat > release_notes.md << 'EOF'
          # LiteLLM Conversation v${{ steps.version.outputs.new_version }}
          
          ## Features
          
          - **Multi-instance Support**: Create separate service instances for Conversation, STT, TTS, and AI Task services
          - **Flexible AI Model Support**: Works with 100+ LLM providers through LiteLLM proxy
          - **Custom Base URL**: Configure your LiteLLM proxy endpoint
          - **Voice Integration**: Full STT and TTS support for voice conversations
          - **AI Task Service**: Generate data and analyze images using vision models
          - **Vision Model Support**: Process camera feeds and images with models like GPT-4 Vision, Claude 3 Vision, Gemini Pro Vision
          - **OpenAI Compatibility**: Drop-in replacement for OpenAI Conversation component
          
          ## Installation
          
          ### HACS Installation (Recommended)
          
          1. Open HACS in your Home Assistant instance
          2. Go to "Integrations"
          3. Click the three dots menu in the top right
          4. Select "Custom repositories"
          5. Add this repository URL: `https://github.com/acaranta/litellm_conversation`
          6. Select "Integration" as the category
          7. Click "Add"
          8. Search for "LiteLLM Conversation" in HACS
          9. Click "Install"
          10. Restart Home Assistant
          
          ## Supported Services
          
          - **Conversation Agent**: Full conversation support with any LLM model
          - **Speech-to-Text (STT)**: Audio transcription using Whisper and compatible models
          - **Text-to-Speech (TTS)**: Voice synthesis with various voice options
          - **AI Task**: Data generation and image analysis with vision models
          
          ## Technical Notes
          
          This release follows semantic versioning for HACS compatibility. The version number matches the `manifest.json` version.
          
          For full documentation, see the [README](https://github.com/acaranta/litellm_conversation/blob/main/README.md).
          EOF

      - name: Create ZIP archive for HACS
        run: |
          cd custom_components/litellm_conversation
          zip -r ../../litellm_conversation.zip .
          cd ../..

      - name: Create Release
        uses: softprops/action-gh-release@v2
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        with:
          tag_name: v${{ steps.version.outputs.new_version }}
          name: v${{ steps.version.outputs.new_version }}
          body_path: release_notes.md
          draft: false
          prerelease: false
          files: |
            litellm_conversation.zip